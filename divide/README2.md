## 0ë‹¨ê³„ : ê¸°ë³¸ Setting (Vessl) 
(1) pip3 install packaging
(2) pdf 25p : Create SSH key ë¶€ë¶„
(3) pdf 25p : Add SSH key to your VESSL account ë¶€ë¶„
(4) vessl workspace vscode

## ğŸ“¦ 1ë‹¨ê³„: Miniconda ì„¤ì¹˜

### 1. Miniconda ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ ë‹¤ìš´ë¡œë“œ
```bash
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
```

### 2. ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
```bash
bash Miniconda3-latest-Linux-x86_64.sh
```
#### ì„¤ì¹˜ ì¤‘ ì„ íƒ ì‚¬í•­:
* ë¼ì´ì„ ìŠ¤ ë™ì˜: `yes`
* ì„¤ì¹˜ ê²½ë¡œ: ê¸°ë³¸ê°’ (`/root/miniconda3` ë“±)
* `conda init` ì‹¤í–‰ ì—¬ë¶€: `yes` ê¶Œì¥

## ğŸŒ€ 2ë‹¨ê³„: ì‰˜ ì´ˆê¸°í™”
ì„¤ì¹˜ ì§í›„ì—ëŠ” ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ í™˜ê²½ ì ìš©:
```bash
source ~/.bashrc
```
ë§Œì•½ ì—¬ì „íˆ `conda` ëª…ë ¹ì´ ì•ˆ ëœë‹¤ë©´:
```bash
eval "$(/root/miniconda3/bin/conda shell.bash hook)"
```

## Installation NEW
conda create -n patch_matters_39 python=3.9 -y
conda activate patch_matters_39

# PyTorch 1.13.1 + cu116 ì„¤ì¹˜ (Python 3.9ìš© íœ  ì‚¬ìš©)
pip install https://download.pytorch.org/whl/cu116/torch-1.13.1%2Bcu116-cp39-cp39-linux_x86_64.whl
pip install https://download.pytorch.org/whl/cu116/torchvision-0.14.1%2Bcu116-cp39-cp39-linux_x86_64.whl
pip install torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu116

# ê·¸ ë‹¤ìŒì— requirements.txt ì„¤ì¹˜
pip install -r requirements.txt

# ########################################################################################

## Usage_ parameter íŒŒì¼ì´ë‘ json íŒŒì¼ì€ ë¡œì»¬ì— ë‹¤ìš´ ë°›ì€ ë‹¤ìŒ, explorerì— ë“œë˜ê·¸
# ë¶ˆí¸í•˜ì§€ë§Œ ì•„ì§ê¹Œì§„ workplace resetë˜ë©´ ë°˜ë³µí•´ì•¼í•¨

`ovdet/checkpoints`
- clip_vitb32.pth
- res50_fpn_soco_star_400.pth
- this_repo_R-50-FPN_CLIP_iter_90000.pth

`ovdet/data/coco/annotations`
- instances_train2017.json
- instances_val2017.json

`ovdet/data/coco/wusize`
- captions_train2017_tags_allcaps.json
- instances_train2017_base.json
- instances_train2017_novel.json
- instances_val2017_base.json
- instances_val2017_novel.json


### ì´ì œ... Divide InferenceëŠ” 2ê°€ì§€ì„... generate_four_box.py & get_main_box.py
# ####################Patch Matters Divide í™˜ê²½ êµ¬ì¶• ë° generate\_four\_box ì‹¤í–‰ ê°€ì´ë“œ
# ì•„ê¹Œ ìœ„ì—ì„œ ë§Œë“  ê°€ìƒí™˜ê²½ê³¼ ë³„ë„ë¡œ ì´ 2ê°œ íŒŒì¼ì„ ì‹¤í–‰í•˜ëŠ”ê±° ì—ì„œë„ ë³„ë„ ê°€ìƒí™˜ê²½ì„ ë§Œë“¤ì–´ì•¼í•¨í•¨

## ğŸ“¦ 1. Conda í™˜ê²½ êµ¬ì„±
```bash
conda create -n patch_matters_divide python=3.8.19 -y
conda activate patch_matters_divide
```

## âš™ï¸ 2. PyTorch ë° CUDA í˜¸í™˜ ë²„ì „ ì„¤ì¹˜

```bash
# ë³¸ì¸ì˜ GPU ë“œë¼ì´ë²„ì™€ í˜¸í™˜ë˜ëŠ” CUDA ë²„ì „ í™•ì¸ í•„ìš”
# ì˜ˆì‹œ: CUDA 11.6ì„ ì‚¬ìš©í•  ê²½ìš° (GPU ì—†ëŠ” ê²½ìš°ì—ë„ ì„¤ì¹˜ëŠ” í•„ìš”í•¨)
pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 --index-url https://download.pytorch.org/whl/cu116
```

> â— **ì£¼ì˜**: ë¡œì»¬ì—ì„œ GPUê°€ ì—†ì„ ê²½ìš° CUDA ë””ë°”ì´ìŠ¤ ì˜¤ë¥˜ ë°œìƒí•¨. í•™ìŠµ/ì¶”ë¡ ì€ ì„œë²„ì—ì„œ ì§„í–‰ ê¶Œì¥.

---

## ğŸ“‚ 3. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜

```bash
# mmcvëŠ” ì•„ë˜ì™€ ê°™ì´ CUDA, torch ë²„ì „ì— ë§ê²Œ ì„¤ì¹˜
pip install mmcv==2.0.1 -f https://download.openmmlab.com/mmcv/dist/cu116/torch1.13/index.html
pip install mmdet==3.1.0
pip install mmengine==0.10.1

# ì´ê±´ í•œë²ˆë§Œ í•˜ë©´ ë¨
apt update
apt install -y libgl1 

# ì„¤ì¹˜ í™•ì¸
python -c "from mmdet.apis import DetInferencer; print('âœ… DetInferencer import OK')"

# ê¸°íƒ€ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬
pip install opencv-python-headless rich pillow tqdm
pip install ftfy


## ğŸ“ 4. ë ˆí¬ êµ¬ì„±

```
patchmatters-vessl/
â”œâ”€â”€ divide/
â”‚   â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ checkpoints/  â† âœ… í•™ìŠµëœ ëª¨ë¸ weight ì €ì¥
â”‚   â”œâ”€â”€ data/         â† âœ… ê²°ê³¼ json ì €ì¥ í´ë” (ì—†ìœ¼ë©´ ìƒì„± í•„ìš”)
â”‚   â”œâ”€â”€ ovdet/        â† âœ… custom ëª¨ë¸ ì •ì˜
â”‚   â”œâ”€â”€ sample_tools/   # ê± tools
â”‚   â”œâ”€â”€ true_box_sample.py
â”‚   â””â”€â”€ generate_four_box.py
â”œâ”€â”€ coco_image/
â”‚   â””â”€â”€ coco_sample_data_Image_Textualization/ â† âœ… ì¶”ë¡ í•  ì´ë¯¸ì§€ ìœ„ì¹˜
```

## âœï¸ 5. generate\_four\_box.py ì½”ë“œ ìˆ˜ì • ì‚¬í•­

### 1. argparse â†’ `arg` ëŒ€ì‹  `args`ë¡œ ì „ë©´ ìˆ˜ì •:

```python
arg = argparse.ArgumentParser()
...
args = arg.parse_args()
```

**ìˆ˜ì • í•­ëª©ë“¤:**

* `arg.image_folder â†’ args.image_folder`
* `arg.four_box_save_path â†’ args.four_box_save_path`
* `arg.object_box_save_path â†’ args.object_box_save_path`
* ê¸°íƒ€ `arg.`ë¡œ ë˜ì–´ìˆë˜ ëª¨ë“  ë³€ìˆ˜ â†’ `args.`ë¡œ êµì²´

### 2. GPUê°€ ì—†ëŠ” ê²½ìš° ì—ëŸ¬ ë°©ì§€ìš© ë””ë°”ì´ìŠ¤ ëª…ì‹œ

```python
inference = DetInferencer(model=args.model_config_file, weights=args.checkpoint_file, device='cpu')
```
> âš ï¸ `argparse`ì—ì„œ `--device`ë¥¼ ì¸ìë¡œ ë°›ì§€ ì•Šê¸° ë•Œë¬¸ì—, ë””ë°”ì´ìŠ¤ëŠ” ì½”ë“œ ë‚´ì—ì„œ ì§ì ‘ `device='cpu'`ë¡œ ëª…ì‹œí•´ì•¼ í•¨

---
# ê·¸ì™¸ inference í•˜ë©´ì„œ ëª‡ ê°œì˜ ì¶”ê°€ ìˆ˜ì •ì„ ì§„í–‰í•¨
# ì§€ê¸ˆ ìƒê°ë‚˜ëŠ”ê±´.... divide/ovdet/models/roi_heads/baron_bbox_heads/bbox_head.py
# 
## â–¶ï¸ 6. ì‹¤í–‰ ëª…ë ¹ì–´ (ë¡œì»¬ or ì„œë²„)

```bash
python /root/patch_matters_re-1/divide/generate_four_box.py \
  --model_config_file "/root/patch_matters_re-1/divide/configs/baron/ov_coco/baron_kd_faster_rcnn_r50_fpn_syncbn_90kx2.py" \
  --checkpoint_file "/root/patch_matters_re-1/divide/ovdet/checkpoints/iter_90000.pth" \
  --image_folder "/root/patch_matters_re-1/coco_image/coco_sample_data_Image_Textualization" \
  --four_box_save_path "/root/patch_matters_re-1/divide/checkpoints/four_box.json" \
  --object_box_save_path "/root/patch_matters_re-1/divide/checkpoints/object_box.json"

```
# ##############################################################################################################################
# ë¶ˆí¸í¸í•˜ì§€ë§Œ ë‹¤ì‹œ ì‹¤í–‰í•  ë–„ ì•„ë˜ì™€ ê°™ì´ ì§„í–‰ì„ ë°˜ë³µí–ˆìŒ 
### 1. Miniconda ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ ë‹¤ìš´ë¡œë“œ
```bash
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh

bash Miniconda3-latest-Linux-x86_64.sh
source /root/miniconda3/etc/profile.d/conda.sh
source ~/.bashrc

conda activate patch_matters_divide
```

# ##############################################################################################################################

# #######################################################  get_main_box.py ì‹¤í–‰ ê°€ì´ë“œ
ğŸ“‚ 1. ì‚¬ì „ ì¤€ë¹„
generate_four_box.py ì‹¤í–‰ ì™„ë£Œ í›„ ì•„ë˜ ë‘ íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•´ì•¼ í•¨
object_box.json
 -> object_box_save_path "/root/patch_matters_re-1/divide/checkpoints/object_box.json
ì´ë¯¸ì§€ í´ë” (your image folder)
 -> image_folder "/root/patch_matters_re-1/coco_image/coco_sample_data_Image_Textualization"

âœï¸ 2. get_main_box.py ì½”ë“œ í™•ì¸ ì‚¬í•­
ì½”ë“œ ë‚´ì— arg. ìœ¼ë¡œ ë˜ì–´ìˆëŠ”ê±° args.ë¡œ ë°”ê¿”ì¤˜ì•¼í•¨

# ê·¸ë¦¬ê³  ì•„ë˜ì™€ ê°™ì´ ë³€ê²½
arg.add_argument('--llm_path', type=str, help='LLM model', default='cache/huggingface/hub/mate-llama-3.1-8b-instruct')
-> arg.add_argument('--llm_path', type=str, help='LLM model', default='meta-llama/Meta-Llama-3-8B-Instruct')

âš ï¸ 3. ì¶”ê°€ë¡œ ë„£ì€ ì½”ë“œ (ê°€ìƒí™˜ê²½ ë‚´ ì„¤ì¹˜ í•„ìš”)
pip install transformers
pip install icecream
pip install 'accelerate>=0.26.0'
huggingface-cli login
# ì¤‘ê°„ì— í† í°ì…ë ¥í•˜ë¼ê³  í•˜ëŠ”ë°, ê·¸ ê°’ì€ ì•„ë˜ ë°©ì‹ìœ¼ë¡œ ê°€ì ¸ì˜´ì˜´
ì´í›„ ì•„ë˜ ë§í¬ë¡œ ì´ë™í•˜ì—¬ í† í° ìƒì„±:
ğŸ‘‰ https://huggingface.co/settings/tokens
"New token" ìƒì„±
ì´ë¦„: ì˜ˆ) llama-access
ê¶Œí•œ: âœ… ìµœì†Œ read ê¶Œí•œ ì´ìƒ
ìƒì„±ëœ í† í°ì„ ë³µì‚¬í•´ì„œ ì§€ê¸ˆ í„°ë¯¸ë„ì— ë¶™ì—¬ë„£ê³  Enter

pip install --upgrade jinja2
pip install --upgrade transformers
mkdir -p ovdet


############################# get_main_box.pyì—ì„œ ì¶”ê°€ ì½”ë“œ ìˆ˜ì •1
# def generate_description(image_path, model, vis_processors, prompt=None):
#     image = Image.open(image_path).convert("RGB")
#     inputs = vis_processors(images=image, return_tensors="pt").to(model.device, torch.float16)
#     generated_ids = model.generate(**inputs
#                                    )
#     generated_text = vis_processors.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()
#     return generated_text
###############################################################################################
def generate_description(image_path, model, processor):
    from PIL import Image
    import torch

    image = Image.open(image_path).convert("RGB")

    prompt = "Describe this image in one sentence."

    # ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ë™ì‹œ ì…ë ¥
    inputs = processor(images=image, text=prompt, return_tensors="pt").to(model.device, dtype=torch.float16)

    # generate í˜¸ì¶œ
    generated_ids = model.generate(**inputs, max_new_tokens=30)

    # í…ìŠ¤íŠ¸ ë””ì½”ë”©
    generated_text = processor.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()
    return generated_text

############################# get_main_box.pyì—ì„œ ì¶”ê°€ ì½”ë“œ ìˆ˜ì •2
# def re_match(input_string):
#     matched_content = re.findall(r"\[.*?\]", input_string)
#     cleaned_items = matched_content[0][1:-1].replace("'", "").strip()


#     return [cleaned_items] if "," not in cleaned_items else [item.strip() for item in cleaned_items.split(",")]
#################################################################################################################
def re_match(common_objects):
    pattern = r"\[(.*?)\]"
    matched_content = re.findall(pattern, str(common_objects))
    if not matched_content:
        return []  # ë˜ëŠ” return common_objects, í•„ìš”ì— ë”°ë¼ ì¡°ì •
    cleaned_items = matched_content[0].replace("'", "").strip()
    return [item.strip() for item in cleaned_items.split(",") if item.strip()]
#################################################################################################################

â–¶ï¸ 4. ì‹¤í–‰ ì½”ë“œ
python /root/patch_matters_re-1/divide/get_main_box.py \
  --image_folder /root/patch_matters_re-1/coco_image/coco_sample_data_Image_Textualization \
  --object_box_save_path /root/patch_matters_re-1/divide/checkpoints/object_box.json \
  --main_box_save_path divide/data/main_box.json



# ì—¬ê¸°ê¹Œì§€ í–ˆìœ¼ë©´ divide ë¶€ë¶„ì€ ì™„ë£Œ!! ì´ì œ aggregation ë¶€ë¶„ì„ í•´ì•¼í•¨í•¨